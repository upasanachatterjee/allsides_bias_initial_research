{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total files pre-clean =  5624\n",
      "total files post-clean =  5397\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import polars as pl\n",
    "from utils import get_sample_article_ids\n",
    "topic = \"elections\"\n",
    "\n",
    "def load_json_file_paths_to_df(paths):\n",
    "    df_list = [\n",
    "        pl.read_json(file) for file in paths\n",
    "    ]  # Read each file into a DataFrame\n",
    "    combined_df = pl.concat(df_list, how=\"diagonal\")  # Concatenate all DataFrames\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "dir_path = f\"grouped_json_articles/{topic}\"\n",
    "\n",
    "files = glob.glob(f\"{dir_path}/*.json\")\n",
    "seen_ids = get_sample_article_ids()\n",
    "print(\"total files pre-clean = \", len(files))\n",
    "\n",
    "files_no_samples = [x for x in files if not any([seen in x for seen in seen_ids])]\n",
    "print(\"total files post-clean = \", len(files_no_samples))\n",
    "\n",
    "df = load_json_file_paths_to_df(files_no_samples)\n",
    "pl.Config.set_tbl_rows(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = df.filter(pl.col(\"ID\") == \"qZPpxN4pJD3orXkl\").select(\"content\").item()\n",
    "center = df.filter(pl.col(\"ID\") == \"5JAXnLSys9Po1z0n\").select(\"content\").item()\n",
    "right = df.filter(pl.col(\"ID\") == \"qz7Gy6yC3sryqgXe\").select(\"content\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on file=bert_generated_text/elections/generated_20V8kjXbJsKJaAsV.json,\n",
      "error=Error code: 400 - {'error': {'message': \"Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': \"{\\n   'bias': 'center'\\n}\"}}\n"
     ]
    }
   ],
   "source": [
    "from utils import load_json, convert_text_bias_to_numerical, write_back_file\n",
    "from llama import generate_bias_groq_with_samples, get_groq_client\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils) \n",
    "\n",
    "investigate = glob.glob(f\"bert_generated_text/{topic}/*.json\")\n",
    "client = get_groq_client()\n",
    "file = investigate[0]\n",
    "\n",
    "for file in investigate:\n",
    "    json = load_json(file)\n",
    "    sample = (\"{text: \" + left + \"\\nbias: left}\" \n",
    "                        + \"\\n\\n{text: \" + right + \"\\nbias: right}\"\n",
    "                        + \"\\n\\n{text: \" + center + \"\\nbias: center}\")\n",
    "\n",
    "    prompt = \"{text: \" + json[\"original_text\"] + \"}\"\n",
    "\n",
    "    try:\n",
    "        bias = generate_bias_groq_with_samples(prompt, sample, client)\n",
    "        num_bias = convert_text_bias_to_numerical(bias)\n",
    "\n",
    "        write_back_file(file, {\"llama_bias_with_sample\": num_bias}, json)\n",
    "    except Exception as e:\n",
    "        print(f\"error on file={file},\\nerror={e}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
